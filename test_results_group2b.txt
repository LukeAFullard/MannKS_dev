============================= test session starts ==============================
platform linux -- Python 3.12.12, pytest-9.0.2, pluggy-1.6.0 -- /home/jules/.pyenv/versions/3.12.12/bin/python3.12
cachedir: .pytest_cache
rootdir: /app
configfile: pyproject.toml
collecting ... collected 30 items

tests/test_power.py::test_power_monotonicity PASSED                      [  3%]
tests/test_power.py::test_mdt_calculation PASSED                         [  6%]
tests/test_power.py::test_power_lomb_scargle PASSED                      [ 10%]
tests/test_power.py::test_power_input_dataframe PASSED                   [ 13%]
tests/test_power_features.py::test_power_test_slope_scaling FAILED       [ 16%]
tests/test_power_features.py::test_power_test_dataframe_input FAILED     [ 20%]
tests/test_power_features.py::test_power_test_dataframe_input_prepared FAILED [ 23%]
tests/test_power_features.py::test_power_test_dataframe_error PASSED     [ 26%]
tests/test_power_features.py::test_power_test_invalid_unit FAILED        [ 30%]
tests/test_regional_aggregation.py::TestRegionalAggregation::test_regional_test_basic PASSED [ 33%]
tests/test_regional_aggregation.py::TestRegionalAggregation::test_regional_test_input_validation PASSED [ 36%]
tests/test_regional_aggregation.py::TestRegionalAggregation::test_regional_test_insufficient_data PASSED [ 40%]
tests/test_regional_aggregation.py::TestRegionalAggregation::test_regional_test_tied_direction PASSED [ 43%]
tests/test_rolling.py::test_rolling_trend_numeric PASSED                 [ 46%]
tests/test_rolling.py::test_rolling_trend_datetime PASSED                [ 50%]
tests/test_rolling.py::test_rolling_trend_seasonal PASSED                [ 53%]
tests/test_rolling.py::test_rolling_trend_insufficient_data PASSED       [ 56%]
tests/test_rolling.py::test_compare_periods PASSED                       [ 60%]
tests/test_rolling.py::test_compare_periods_datetime PASSED              [ 63%]
tests/test_rolling.py::test_rolling_input_validation PASSED              [ 66%]
tests/test_rolling_offset.py::test_rolling_trend_offset_fallback PASSED  [ 70%]
tests/test_rolling_trend.py::test_rolling_trend_basic_numeric PASSED     [ 73%]
tests/test_rolling_trend.py::test_rolling_trend_basic_datetime PASSED    [ 76%]
tests/test_rolling_trend.py::test_rolling_trend_min_size PASSED          [ 80%]
tests/test_rolling_trend.py::test_compare_periods PASSED                 [ 83%]
tests/test_rolling_trend.py::test_plot_rolling_trend_execution PASSED    [ 86%]
tests/test_rolling_trend.py::test_rolling_with_dataframe_input PASSED    [ 90%]
tests/test_rolling_trend.py::test_rolling_trend_seasonal PASSED          [ 93%]
tests/test_rolling_trend.py::test_rolling_trend_edge_case_last_point PASSED [ 96%]
tests/test_rolling_trend.py::test_compare_periods_seasonal PASSED        [100%]

=================================== FAILURES ===================================
________________________ test_power_test_slope_scaling _________________________

    def test_power_test_slope_scaling():
        """Verify that slope_scaling works correctly."""
        t = pd.date_range('2020-01-01', periods=100, freq='D')
        x = np.random.normal(0, 1, 100)

        # Define a trend of 1 unit per year.
        # In seconds, this is ~3.17e-8 units/sec.
        # If we pass 1.0 with unit='year', it should be converted to ~3.17e-8.
        # The noise sigma is 1. Over 100 days (~0.27 yr), the trend contribution is 0.27.
        # This is small compared to noise (sigma=1). Power should be low.

>       res = power_test(
            x, t, slopes=[1.0], n_simulations=10, n_surrogates=10,
            slope_scaling='year'
        )

tests/test_power_features.py:19:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x = array([-1.61180117,  0.35974414, -1.37330169, -0.63082103,  1.50856315,
       -1.93575484,  0.79858562, -2.70177238, ...057911,  0.88203156, -1.42561429,  0.05260256,
       -0.78760852, -0.10824646, -0.82833954,  0.06145857, -1.92244631])
t = DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',
               '2020-01-05', '2020-01-06', '202...               '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09'],
              dtype='datetime64[ns]', freq='D')
slopes = [1.0], n_simulations = 10, n_surrogates = 10, alpha = 0.05
surrogate_method = 'auto', random_state = None, surrogate_kwargs = None
slope_scaling = 'year', detrend = False, kwargs = {}
x_input = array([-1.61180117,  0.35974414, -1.37330169, -0.63082103,  1.50856315,
       -1.93575484,  0.79858562, -2.70177238, ...057911,  0.88203156, -1.42561429,  0.05260256,
       -0.78760852, -0.10824646, -0.82833954,  0.06145857, -1.92244631])
data_filtered =        value  censored cen_type t_original             t  original_index
0  -1.611801     False      not 2020-01-01  1...04e+09              98
99 -1.922446     False      not 2020-04-09  1.586390e+09              99

[100 rows x 6 columns]
_ = True
x_arr = array([-1.61180117,  0.35974414, -1.37330169, -0.63082103,  1.50856315,
       -1.93575484,  0.79858562, -2.70177238, ...057911,  0.88203156, -1.42561429,  0.05260256,
       -0.78760852, -0.10824646, -0.82833954,  0.06145857, -1.92244631])
t_numeric = array([1.5778368e+09, 1.5779232e+09, 1.5780096e+09, 1.5780960e+09,
       1.5781824e+09, 1.5782688e+09, 1.5783552e+09,...6e+09, 1.5858720e+09, 1.5859584e+09, 1.5860448e+09,
       1.5861312e+09, 1.5862176e+09, 1.5863040e+09, 1.5863904e+09])
surr_kwargs = {}, min_possible_p = 0.09090909090909091

    def power_test(
        x: Union[np.ndarray, pd.DataFrame],
        t: np.ndarray,
        slopes: Union[List[float], np.ndarray],
        n_simulations: int = 100,
        n_surrogates: int = 1000,
        alpha: float = 0.05,
        surrogate_method: str = 'auto',
        random_state: Optional[int] = None,
        surrogate_kwargs: Optional[dict] = None,
        slope_scaling: Optional[str] = None,
        detrend: bool = False,
        **kwargs
    ) -> PowerResult:
        """
        Estimates the statistical power of the surrogate trend test via Monte Carlo simulation.

        Generates synthetic datasets by injecting deterministic trends into colored noise
        realizations (derived from the input data's spectral properties) and calculating
        the frequency of significant detections.

        Args:
            x (Union[np.ndarray, pd.DataFrame]): Input data (used to define the noise model).
            t (np.ndarray): Time values.
            slopes (Union[List[float], np.ndarray]): List of trend slopes (beta) to test.
            n_simulations (int): Number of Monte Carlo simulations per slope.
            n_surrogates (int): Number of surrogates used in the *inner* significance test.
            alpha (float): Significance level for detection (default 0.05).
            surrogate_method (str): Method for surrogate generation ('auto', 'iaaft', 'lomb_scargle').
                Used for both noise generation and the inner test.
            random_state (Optional[int]): Seed for reproducibility.
            surrogate_kwargs (dict, optional): Additional arguments passed to the surrogate generator
                (e.g., {'dy': errors, 'freq_method': 'log'}).
            slope_scaling (str, optional): The time unit for the provided slopes (e.g., 'year').
                If provided, input slopes are interpreted as 'units per [slope_scaling]' and
                converted to 'units per second' before injection.
                Supports: 's', 'min', 'h', 'D', 'Y' and their full names (e.g. 'year', 'day').
                Default is None (no conversion, interpreted as units per second or raw time unit).
            detrend (bool): If True, linearly detrends the input `x` before generating surrogates.
                This prevents an existing strong trend in `x` from inflating the low-frequency
                power of the noise model, which would otherwise reduce the estimated power.
                Default is False (conservative).
            **kwargs: Additional arguments passed to `surrogate_test`.

        Returns:
            PowerResult: Named tuple containing power curve, MDT, and details.
        """
        # Prepare and filter data (handles NaNs and datetime conversion)
        # This ensures Lomb-Scargle and other methods receive clean data.
        # Note: hicensor=False because power_test simulates additive trends on
        # the observed values, not censored logic directly. If the user provides
        # 'censored' flags in kwargs, they are responsible for their meaning.

        # Robustly handle DataFrame input before passing to _prepare_data
        # _prepare_data is strict about requiring 'value', 'censored', 'cen_type'
        # if passing a multi-column DataFrame. power_test only needs the values.
        x_input = x
        if isinstance(x, pd.DataFrame) and 'value' in x.columns:
            x_input = x['value']

        data_filtered, _ = _prepare_data(x_input, t, hicensor=False)

        x_arr = data_filtered['value'].to_numpy()
        t_numeric = data_filtered['t'].to_numpy()

        # Final check for data integrity (e.g. infinite values which _prepare_data might not catch)
        check_data_integrity(x_arr, t_numeric, context="power_test")

        # Check if data was filtered (e.g. NaNs removed)
        # We must align array-like kwargs (e.g. 'dy', 'censored') if provided.
        surr_kwargs = surrogate_kwargs.copy() if surrogate_kwargs else {}
        surr_kwargs.update(kwargs)

        if 'censored' in surr_kwargs and np.any(surr_kwargs['censored']):
            warnings.warn(
                "Censored data simulation in power analysis assumes censoring status and limits "
                "track the simulated trend (i.e., the limit of detection moves with the mean). "
                "This may not reflect fixed detection limits common in environmental data. "
                "Results should be interpreted with caution.",
                UserWarning
            )

        # Check for impossible detection (footgun prevention)
        # The minimum possible p-value with N surrogates is 1 / (N + 1).
        # If this minimum is greater than alpha, no trend can ever be detected.
        min_possible_p = 1.0 / (n_surrogates + 1)
        if min_possible_p > alpha:
>           raise ValueError(
                f"Impossible to detect trends with n_surrogates={n_surrogates} and alpha={alpha}. "
                f"The minimum possible p-value is {min_possible_p:.4f}, which is > {alpha}. "
                f"Please increase n_surrogates (recommend > {int(1/alpha)}) or increase alpha."
            )
E           ValueError: Impossible to detect trends with n_surrogates=10 and alpha=0.05. The minimum possible p-value is 0.0909, which is > 0.05. Please increase n_surrogates (recommend > 20) or increase alpha.

MannKS/power.py:117: ValueError
_______________________ test_power_test_dataframe_input ________________________

    def test_power_test_dataframe_input():
        """Verify robust handling of DataFrame input."""
        t = np.arange(20)
        df = pd.DataFrame({'value': np.random.normal(0, 1, 20), 'censored': False})

        # This previously failed because it flattened the DF. Now it should extract 'value'.
>       res = power_test(df, t, slopes=[0.1], n_simulations=5, n_surrogates=5)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_power_features.py:36:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x =        value  censored
0   0.957463     False
1  -1.047276     False
2   1.694471     False
3  -1.034195     False
4  ...alse
15  0.301257     False
16  0.282328     False
17 -0.167476     False
18  1.595719     False
19  1.940162     False
t = array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
       17, 18, 19])
slopes = [0.1], n_simulations = 5, n_surrogates = 5, alpha = 0.05
surrogate_method = 'auto', random_state = None, surrogate_kwargs = None
slope_scaling = None, detrend = False, kwargs = {}
x_input = 0     0.957463
1    -1.047276
2     1.694471
3    -1.034195
4    -1.067952
5    -1.422035
6     0.011231
7    -1.36464...8
14    0.907596
15    0.301257
16    0.282328
17   -0.167476
18    1.595719
19    1.940162
Name: value, dtype: float64
data_filtered =        value  censored cen_type  t_original     t  original_index
0   0.957463     False      not           0   0.0   ...     False      not          18  18.0              18
19  1.940162     False      not          19  19.0              19
_ = False
x_arr = array([ 0.95746264, -1.04727584,  1.69447099, -1.0341947 , -1.06795161,
       -1.42203462,  0.01123058, -1.36464481, ...818272,  1.02358806, -0.37737789,  0.90759554,
        0.30125731,  0.28232767, -0.16747577,  1.59571873,  1.94016197])
t_numeric = array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19.])
surr_kwargs = {}, min_possible_p = 0.16666666666666666

    def power_test(
        x: Union[np.ndarray, pd.DataFrame],
        t: np.ndarray,
        slopes: Union[List[float], np.ndarray],
        n_simulations: int = 100,
        n_surrogates: int = 1000,
        alpha: float = 0.05,
        surrogate_method: str = 'auto',
        random_state: Optional[int] = None,
        surrogate_kwargs: Optional[dict] = None,
        slope_scaling: Optional[str] = None,
        detrend: bool = False,
        **kwargs
    ) -> PowerResult:
        """
        Estimates the statistical power of the surrogate trend test via Monte Carlo simulation.

        Generates synthetic datasets by injecting deterministic trends into colored noise
        realizations (derived from the input data's spectral properties) and calculating
        the frequency of significant detections.

        Args:
            x (Union[np.ndarray, pd.DataFrame]): Input data (used to define the noise model).
            t (np.ndarray): Time values.
            slopes (Union[List[float], np.ndarray]): List of trend slopes (beta) to test.
            n_simulations (int): Number of Monte Carlo simulations per slope.
            n_surrogates (int): Number of surrogates used in the *inner* significance test.
            alpha (float): Significance level for detection (default 0.05).
            surrogate_method (str): Method for surrogate generation ('auto', 'iaaft', 'lomb_scargle').
                Used for both noise generation and the inner test.
            random_state (Optional[int]): Seed for reproducibility.
            surrogate_kwargs (dict, optional): Additional arguments passed to the surrogate generator
                (e.g., {'dy': errors, 'freq_method': 'log'}).
            slope_scaling (str, optional): The time unit for the provided slopes (e.g., 'year').
                If provided, input slopes are interpreted as 'units per [slope_scaling]' and
                converted to 'units per second' before injection.
                Supports: 's', 'min', 'h', 'D', 'Y' and their full names (e.g. 'year', 'day').
                Default is None (no conversion, interpreted as units per second or raw time unit).
            detrend (bool): If True, linearly detrends the input `x` before generating surrogates.
                This prevents an existing strong trend in `x` from inflating the low-frequency
                power of the noise model, which would otherwise reduce the estimated power.
                Default is False (conservative).
            **kwargs: Additional arguments passed to `surrogate_test`.

        Returns:
            PowerResult: Named tuple containing power curve, MDT, and details.
        """
        # Prepare and filter data (handles NaNs and datetime conversion)
        # This ensures Lomb-Scargle and other methods receive clean data.
        # Note: hicensor=False because power_test simulates additive trends on
        # the observed values, not censored logic directly. If the user provides
        # 'censored' flags in kwargs, they are responsible for their meaning.

        # Robustly handle DataFrame input before passing to _prepare_data
        # _prepare_data is strict about requiring 'value', 'censored', 'cen_type'
        # if passing a multi-column DataFrame. power_test only needs the values.
        x_input = x
        if isinstance(x, pd.DataFrame) and 'value' in x.columns:
            x_input = x['value']

        data_filtered, _ = _prepare_data(x_input, t, hicensor=False)

        x_arr = data_filtered['value'].to_numpy()
        t_numeric = data_filtered['t'].to_numpy()

        # Final check for data integrity (e.g. infinite values which _prepare_data might not catch)
        check_data_integrity(x_arr, t_numeric, context="power_test")

        # Check if data was filtered (e.g. NaNs removed)
        # We must align array-like kwargs (e.g. 'dy', 'censored') if provided.
        surr_kwargs = surrogate_kwargs.copy() if surrogate_kwargs else {}
        surr_kwargs.update(kwargs)

        if 'censored' in surr_kwargs and np.any(surr_kwargs['censored']):
            warnings.warn(
                "Censored data simulation in power analysis assumes censoring status and limits "
                "track the simulated trend (i.e., the limit of detection moves with the mean). "
                "This may not reflect fixed detection limits common in environmental data. "
                "Results should be interpreted with caution.",
                UserWarning
            )

        # Check for impossible detection (footgun prevention)
        # The minimum possible p-value with N surrogates is 1 / (N + 1).
        # If this minimum is greater than alpha, no trend can ever be detected.
        min_possible_p = 1.0 / (n_surrogates + 1)
        if min_possible_p > alpha:
>           raise ValueError(
                f"Impossible to detect trends with n_surrogates={n_surrogates} and alpha={alpha}. "
                f"The minimum possible p-value is {min_possible_p:.4f}, which is > {alpha}. "
                f"Please increase n_surrogates (recommend > {int(1/alpha)}) or increase alpha."
            )
E           ValueError: Impossible to detect trends with n_surrogates=5 and alpha=0.05. The minimum possible p-value is 0.1667, which is > 0.05. Please increase n_surrogates (recommend > 20) or increase alpha.

MannKS/power.py:117: ValueError
___________________ test_power_test_dataframe_input_prepared ___________________

    def test_power_test_dataframe_input_prepared():
        """Verify robust handling of prepare_censored_data output."""
        t = np.arange(20)
        # Even if we have censored data, power_test treats it as noise source (values only).
        df_prep = prepare_censored_data(['1', '2', '3'] * 6 + ['4', '5']) # 20 items

        # Should run without error
>       res = power_test(df_prep, t, slopes=[0.1], n_simulations=5, n_surrogates=5)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_power_features.py:47:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x =     value  censored cen_type
0     1.0     False      not
1     2.0     False      not
2     3.0     False      not
3 ...not
16    2.0     False      not
17    3.0     False      not
18    4.0     False      not
19    5.0     False      not
t = array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
       17, 18, 19])
slopes = [0.1], n_simulations = 5, n_surrogates = 5, alpha = 0.05
surrogate_method = 'auto', random_state = None, surrogate_kwargs = None
slope_scaling = None, detrend = False, kwargs = {}
x_input = 0     1.0
1     2.0
2     3.0
3     1.0
4     2.0
5     3.0
6     1.0
7     2.0
8     3.0
9     1.0
10    2.0
11    3.0
12    1.0
13    2.0
14    3.0
15    1.0
16    2.0
17    3.0
18    4.0
19    5.0
Name: value, dtype: float64
data_filtered =     value  censored cen_type  t_original     t  original_index
0     1.0     False      not           0   0.0         ...4.0     False      not          18  18.0              18
19    5.0     False      not          19  19.0              19
_ = False
x_arr = array([1., 2., 3., 1., 2., 3., 1., 2., 3., 1., 2., 3., 1., 2., 3., 1., 2.,
       3., 4., 5.])
t_numeric = array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19.])
surr_kwargs = {}, min_possible_p = 0.16666666666666666

    def power_test(
        x: Union[np.ndarray, pd.DataFrame],
        t: np.ndarray,
        slopes: Union[List[float], np.ndarray],
        n_simulations: int = 100,
        n_surrogates: int = 1000,
        alpha: float = 0.05,
        surrogate_method: str = 'auto',
        random_state: Optional[int] = None,
        surrogate_kwargs: Optional[dict] = None,
        slope_scaling: Optional[str] = None,
        detrend: bool = False,
        **kwargs
    ) -> PowerResult:
        """
        Estimates the statistical power of the surrogate trend test via Monte Carlo simulation.

        Generates synthetic datasets by injecting deterministic trends into colored noise
        realizations (derived from the input data's spectral properties) and calculating
        the frequency of significant detections.

        Args:
            x (Union[np.ndarray, pd.DataFrame]): Input data (used to define the noise model).
            t (np.ndarray): Time values.
            slopes (Union[List[float], np.ndarray]): List of trend slopes (beta) to test.
            n_simulations (int): Number of Monte Carlo simulations per slope.
            n_surrogates (int): Number of surrogates used in the *inner* significance test.
            alpha (float): Significance level for detection (default 0.05).
            surrogate_method (str): Method for surrogate generation ('auto', 'iaaft', 'lomb_scargle').
                Used for both noise generation and the inner test.
            random_state (Optional[int]): Seed for reproducibility.
            surrogate_kwargs (dict, optional): Additional arguments passed to the surrogate generator
                (e.g., {'dy': errors, 'freq_method': 'log'}).
            slope_scaling (str, optional): The time unit for the provided slopes (e.g., 'year').
                If provided, input slopes are interpreted as 'units per [slope_scaling]' and
                converted to 'units per second' before injection.
                Supports: 's', 'min', 'h', 'D', 'Y' and their full names (e.g. 'year', 'day').
                Default is None (no conversion, interpreted as units per second or raw time unit).
            detrend (bool): If True, linearly detrends the input `x` before generating surrogates.
                This prevents an existing strong trend in `x` from inflating the low-frequency
                power of the noise model, which would otherwise reduce the estimated power.
                Default is False (conservative).
            **kwargs: Additional arguments passed to `surrogate_test`.

        Returns:
            PowerResult: Named tuple containing power curve, MDT, and details.
        """
        # Prepare and filter data (handles NaNs and datetime conversion)
        # This ensures Lomb-Scargle and other methods receive clean data.
        # Note: hicensor=False because power_test simulates additive trends on
        # the observed values, not censored logic directly. If the user provides
        # 'censored' flags in kwargs, they are responsible for their meaning.

        # Robustly handle DataFrame input before passing to _prepare_data
        # _prepare_data is strict about requiring 'value', 'censored', 'cen_type'
        # if passing a multi-column DataFrame. power_test only needs the values.
        x_input = x
        if isinstance(x, pd.DataFrame) and 'value' in x.columns:
            x_input = x['value']

        data_filtered, _ = _prepare_data(x_input, t, hicensor=False)

        x_arr = data_filtered['value'].to_numpy()
        t_numeric = data_filtered['t'].to_numpy()

        # Final check for data integrity (e.g. infinite values which _prepare_data might not catch)
        check_data_integrity(x_arr, t_numeric, context="power_test")

        # Check if data was filtered (e.g. NaNs removed)
        # We must align array-like kwargs (e.g. 'dy', 'censored') if provided.
        surr_kwargs = surrogate_kwargs.copy() if surrogate_kwargs else {}
        surr_kwargs.update(kwargs)

        if 'censored' in surr_kwargs and np.any(surr_kwargs['censored']):
            warnings.warn(
                "Censored data simulation in power analysis assumes censoring status and limits "
                "track the simulated trend (i.e., the limit of detection moves with the mean). "
                "This may not reflect fixed detection limits common in environmental data. "
                "Results should be interpreted with caution.",
                UserWarning
            )

        # Check for impossible detection (footgun prevention)
        # The minimum possible p-value with N surrogates is 1 / (N + 1).
        # If this minimum is greater than alpha, no trend can ever be detected.
        min_possible_p = 1.0 / (n_surrogates + 1)
        if min_possible_p > alpha:
>           raise ValueError(
                f"Impossible to detect trends with n_surrogates={n_surrogates} and alpha={alpha}. "
                f"The minimum possible p-value is {min_possible_p:.4f}, which is > {alpha}. "
                f"Please increase n_surrogates (recommend > {int(1/alpha)}) or increase alpha."
            )
E           ValueError: Impossible to detect trends with n_surrogates=5 and alpha=0.05. The minimum possible p-value is 0.1667, which is > 0.05. Please increase n_surrogates (recommend > 20) or increase alpha.

MannKS/power.py:117: ValueError
_________________________ test_power_test_invalid_unit _________________________

    def test_power_test_invalid_unit():
        """Verify that invalid slope_scaling raises ValueError."""
        t = pd.date_range('2020-01-01', periods=100, freq='D')
        x = np.random.normal(0, 1, 100)

        with pytest.raises(ValueError, match="Invalid `slope_scaling` parameter"):
>           power_test(x, t, slopes=[1.0], n_simulations=5, n_surrogates=5, slope_scaling='foobar')

tests/test_power_features.py:65:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x = array([ 0.3749017 , -0.34314973,  1.91845547,  1.9501677 , -0.14342769,
       -1.39332332, -0.48090897,  0.95725775, ...499693,  1.71777775, -0.29452017,  1.24536787,
        0.18773007, -0.06962847, -1.54707899, -1.26224822,  1.17591011])
t = DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',
               '2020-01-05', '2020-01-06', '202...               '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09'],
              dtype='datetime64[ns]', freq='D')
slopes = [1.0], n_simulations = 5, n_surrogates = 5, alpha = 0.05
surrogate_method = 'auto', random_state = None, surrogate_kwargs = None
slope_scaling = 'foobar', detrend = False, kwargs = {}
x_input = array([ 0.3749017 , -0.34314973,  1.91845547,  1.9501677 , -0.14342769,
       -1.39332332, -0.48090897,  0.95725775, ...499693,  1.71777775, -0.29452017,  1.24536787,
        0.18773007, -0.06962847, -1.54707899, -1.26224822,  1.17591011])
data_filtered =        value  censored cen_type t_original             t  original_index
0   0.374902     False      not 2020-01-01  1...04e+09              98
99  1.175910     False      not 2020-04-09  1.586390e+09              99

[100 rows x 6 columns]
_ = True
x_arr = array([ 0.3749017 , -0.34314973,  1.91845547,  1.9501677 , -0.14342769,
       -1.39332332, -0.48090897,  0.95725775, ...499693,  1.71777775, -0.29452017,  1.24536787,
        0.18773007, -0.06962847, -1.54707899, -1.26224822,  1.17591011])
t_numeric = array([1.5778368e+09, 1.5779232e+09, 1.5780096e+09, 1.5780960e+09,
       1.5781824e+09, 1.5782688e+09, 1.5783552e+09,...6e+09, 1.5858720e+09, 1.5859584e+09, 1.5860448e+09,
       1.5861312e+09, 1.5862176e+09, 1.5863040e+09, 1.5863904e+09])
surr_kwargs = {}, min_possible_p = 0.16666666666666666

    def power_test(
        x: Union[np.ndarray, pd.DataFrame],
        t: np.ndarray,
        slopes: Union[List[float], np.ndarray],
        n_simulations: int = 100,
        n_surrogates: int = 1000,
        alpha: float = 0.05,
        surrogate_method: str = 'auto',
        random_state: Optional[int] = None,
        surrogate_kwargs: Optional[dict] = None,
        slope_scaling: Optional[str] = None,
        detrend: bool = False,
        **kwargs
    ) -> PowerResult:
        """
        Estimates the statistical power of the surrogate trend test via Monte Carlo simulation.

        Generates synthetic datasets by injecting deterministic trends into colored noise
        realizations (derived from the input data's spectral properties) and calculating
        the frequency of significant detections.

        Args:
            x (Union[np.ndarray, pd.DataFrame]): Input data (used to define the noise model).
            t (np.ndarray): Time values.
            slopes (Union[List[float], np.ndarray]): List of trend slopes (beta) to test.
            n_simulations (int): Number of Monte Carlo simulations per slope.
            n_surrogates (int): Number of surrogates used in the *inner* significance test.
            alpha (float): Significance level for detection (default 0.05).
            surrogate_method (str): Method for surrogate generation ('auto', 'iaaft', 'lomb_scargle').
                Used for both noise generation and the inner test.
            random_state (Optional[int]): Seed for reproducibility.
            surrogate_kwargs (dict, optional): Additional arguments passed to the surrogate generator
                (e.g., {'dy': errors, 'freq_method': 'log'}).
            slope_scaling (str, optional): The time unit for the provided slopes (e.g., 'year').
                If provided, input slopes are interpreted as 'units per [slope_scaling]' and
                converted to 'units per second' before injection.
                Supports: 's', 'min', 'h', 'D', 'Y' and their full names (e.g. 'year', 'day').
                Default is None (no conversion, interpreted as units per second or raw time unit).
            detrend (bool): If True, linearly detrends the input `x` before generating surrogates.
                This prevents an existing strong trend in `x` from inflating the low-frequency
                power of the noise model, which would otherwise reduce the estimated power.
                Default is False (conservative).
            **kwargs: Additional arguments passed to `surrogate_test`.

        Returns:
            PowerResult: Named tuple containing power curve, MDT, and details.
        """
        # Prepare and filter data (handles NaNs and datetime conversion)
        # This ensures Lomb-Scargle and other methods receive clean data.
        # Note: hicensor=False because power_test simulates additive trends on
        # the observed values, not censored logic directly. If the user provides
        # 'censored' flags in kwargs, they are responsible for their meaning.

        # Robustly handle DataFrame input before passing to _prepare_data
        # _prepare_data is strict about requiring 'value', 'censored', 'cen_type'
        # if passing a multi-column DataFrame. power_test only needs the values.
        x_input = x
        if isinstance(x, pd.DataFrame) and 'value' in x.columns:
            x_input = x['value']

        data_filtered, _ = _prepare_data(x_input, t, hicensor=False)

        x_arr = data_filtered['value'].to_numpy()
        t_numeric = data_filtered['t'].to_numpy()

        # Final check for data integrity (e.g. infinite values which _prepare_data might not catch)
        check_data_integrity(x_arr, t_numeric, context="power_test")

        # Check if data was filtered (e.g. NaNs removed)
        # We must align array-like kwargs (e.g. 'dy', 'censored') if provided.
        surr_kwargs = surrogate_kwargs.copy() if surrogate_kwargs else {}
        surr_kwargs.update(kwargs)

        if 'censored' in surr_kwargs and np.any(surr_kwargs['censored']):
            warnings.warn(
                "Censored data simulation in power analysis assumes censoring status and limits "
                "track the simulated trend (i.e., the limit of detection moves with the mean). "
                "This may not reflect fixed detection limits common in environmental data. "
                "Results should be interpreted with caution.",
                UserWarning
            )

        # Check for impossible detection (footgun prevention)
        # The minimum possible p-value with N surrogates is 1 / (N + 1).
        # If this minimum is greater than alpha, no trend can ever be detected.
        min_possible_p = 1.0 / (n_surrogates + 1)
        if min_possible_p > alpha:
>           raise ValueError(
                f"Impossible to detect trends with n_surrogates={n_surrogates} and alpha={alpha}. "
                f"The minimum possible p-value is {min_possible_p:.4f}, which is > {alpha}. "
                f"Please increase n_surrogates (recommend > {int(1/alpha)}) or increase alpha."
            )
E           ValueError: Impossible to detect trends with n_surrogates=5 and alpha=0.05. The minimum possible p-value is 0.1667, which is > 0.05. Please increase n_surrogates (recommend > 20) or increase alpha.

MannKS/power.py:117: ValueError

During handling of the above exception, another exception occurred:

    def test_power_test_invalid_unit():
        """Verify that invalid slope_scaling raises ValueError."""
        t = pd.date_range('2020-01-01', periods=100, freq='D')
        x = np.random.normal(0, 1, 100)

>       with pytest.raises(ValueError, match="Invalid `slope_scaling` parameter"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: Regex pattern did not match.
E         Expected regex: 'Invalid `slope_scaling` parameter'
E         Actual message: 'Impossible to detect trends with n_surrogates=5 and alpha=0.05. The minimum possible p-value is 0.1667, which is > 0.05. Please increase n_surrogates (recommend > 20) or increase alpha.'

tests/test_power_features.py:64: AssertionError
=============================== warnings summary ===============================
tests/test_power.py::test_power_monotonicity
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 6 (rel_change=2.15e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_power.py::test_power_monotonicity
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 7 (rel_change=1.27e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_power.py::test_power_monotonicity
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 3 (rel_change=2.85e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_power.py::test_power_monotonicity
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 6 (rel_change=1.01e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_power.py::test_power_monotonicity
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 4 (rel_change=1.57e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_power.py::test_power_monotonicity
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 4 (rel_change=3.19e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_power.py::test_mdt_calculation
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 4 (rel_change=1.11e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_power.py::test_mdt_calculation
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 5 (rel_change=2.11e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_power.py::test_power_input_dataframe
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 3 (rel_change=6.24e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_power.py::test_power_input_dataframe
  /app/MannKS/_surrogate.py:113: UserWarning: IAAFT convergence stalled at iter 4 (rel_change=1.86e-03). This often indicates data with unusual spectral properties or too few observations. The result may be suboptimal but is usually acceptable.
    warnings.warn(

tests/test_rolling.py::test_rolling_trend_seasonal
  /app/MannKS/seasonal_trend_test.py:1055: UserWarning: Variance near zero, Z-score may be unreliable
    warnings.warn(w_str, UserWarning)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/test_power_features.py::test_power_test_slope_scaling - ValueErr...
FAILED tests/test_power_features.py::test_power_test_dataframe_input - ValueE...
FAILED tests/test_power_features.py::test_power_test_dataframe_input_prepared
FAILED tests/test_power_features.py::test_power_test_invalid_unit - Assertion...
================== 4 failed, 26 passed, 11 warnings in 15.90s ==================
